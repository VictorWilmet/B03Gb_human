---
title: "Carnet de notes"
output: html_notebook
---

```{r}
SciViews::R
```

# Introduction

Un an après la collecte de données biométriques humaines par des étudiants dans le cadre du cours de science des données, une nouvelle analyse de ces données a été réalisée à l'aide de nouveaux outils (en lien avec le modèle linéaire). 

Les données utilisées au cours de cette étude sont disponibles au fomat csv à l'adresse suivante : 
https://docs.google.com/spreadsheets/d/e/2PACX-1vSfY7b0ICF64uv9vIYi8Jg38Rw3pKvLHC5TW0XOZYVQ4ce2dTmXGM5Cm8J922MsYm_fk75DKOK2wC4b/pub?output=csv

Les métadonnées associées au jeu de données sont disponnibles sur ce googledoc : 
https://docs.google.com/spreadsheets/d/1j55bB9YEAVbS4eRE-i6L-NEYhHXua-dxs-aQr_qko7k/edit?usp=sharing

# Analyses

```{r}
biometry <- readr::read_csv("biometrie_humaine_2019 - Feuille 1.csv", locale = readr::locale(decimal_mark = ",")) %>.%
  mutate(., tour_taille = as.numeric(tour_taille), tour_hanche = as.numeric(tour_hanche))
  

biometry <- drop_na(biometry)

biometry <- labelise(biometry, 
  label=list(
    genre = "genre",
    taille = "taille",
    age = "age",
    masse = "masse",
    masse_perso = "masse personne",
    masse_ref = "masse référence",
    tour_hanche = "tour de hanche",
    tour_taille = "tour de taille",
    tour_poignet = "tour de poignet",
    activite_phy = "activité physique",
    conso_alcool = "consommation alcool",
    fast_food = "fast food",
    temps_assis = "temps assis",
    temps_sommeil = "temps sommeil",
    milieu_vie = "milieu de vie",
    soda = "soda",
    tabac = "tabac",
    profession = "profession",
    conso_eau = "consommation eau"),
  units=list(
    taille = "cm",
    age = "ans",
    masse = "Kg",
    masse_perso = "Kg",
    masse_ref = "Kg",
    tour_hanche = "m",
    tour_taille = "m",
    tour_poignet = "m",
    activite_phy = "min/sem",
    conso_alcool = "verres/sem",
    temps_assis = "h/jours",
    temps_sommeil = "h/nuits",
    soda = "l/sem",
    tabac = "cig/sem",
    conso_eau = "l/sem")
    )

biometry <- filter(biometry, masse < 200)
```

La colonne "masse" du jeu de données a subi une délétion d'un ensemble de données aux valeurs implausibles (de 300 à plus de 1000 Kg). Une erreur d'encodage a manifestement eu lieu pour un certain nombre d'entre elles.

La thématique: étudier la relation entre la masse des individus de l'étude avec leur tour de hanche ou avec leur tour de taille

Observons d'abord la forme du scatter plot obtenu dans chacun des deux cas

```{r}
chart(biometry, masse ~ tour_hanche) +
  geom_point()

chart(biometry, masse ~ tour_taille) +
  geom_point()
```

Une donnée étrange semble avoir le potentiel de compromettre totalement l'analyse des deux cas de figure (un individu a rapporté un tour de taille de 40 cm, ce qui est franchement improbable). Supprimons cette donnée et voyons à nouveau les nuages de points.

```{r}
biometry <- filter(biometry, tour_hanche > 0.5, tour_taille > 0.5)

aa <- chart(biometry, masse ~ tour_hanche) +
  geom_point()

ab <- chart(biometry, masse ~ tour_taille) +
  geom_point() +

ac <- combine_charts(list(aa, ab))

ac
```

Les données sélectionnées sont maintenant prêtes à être analysées. Dans les deux cas, une droite de régression linéaire semble appropriée. Essayons plusieurs modélisations (linéaire simple, polynomiale) et voyons lequel semble mieux représenter le nuage de points obtenu.

```{r}

summary(lm_sh <- lm(data = biometry, masse ~ tour_hanche))
lm_sh %>.% (function (lm, model = lm[["model"]], vars = names(model))
  chart(model, aes_string(x = vars[2], y = vars[1])) +
  geom_point() +
  stat_smooth(method = "lm", formula = y ~ x))(.) +
  ggtitle("Régression linéaire simple, masse en fonction du tour de hanche")
```

Voici une modélisation graphique de la régression linéaire mettant en évidence la relation entre la masse des individus de l'étude avec leur tour de hanche. Nous pouvons voir que la valeur de R² est de 0.514, la valeur de l'ordonnée à l'origine vaut -33,272 et que la pente de la droite de régression linéaire (en bleu foncé) vaut 107,57. Celle ci est contenue dans une enveloppe de confiance qui est en bleu clair. La p-value obtenue pour cette modélisation est inférieure à 2,2e-16, au seuil alpha fixé à 0,05. A première vue, cette modélisation semble bien représenter la tendance du nuage de points. Vérifions cela en effectuant quelques analyses sur les résidus.

```{r}
a <- lm_sh %>.%
  chart(broom::augment(.), .resid ~ .fitted) +
  geom_point() +
  geom_hline(yintercept = 0) +
  geom_smooth(se = FALSE, method = "loess", formula = y ~ x) +
  labs(x = "Fitted values", y = "Residuals") +
  ggtitle("Residuals vs Fitted")

b <- lm_sh %>.%
  chart(broom::augment(.), sqrt(abs(.std.resid)) ~ .fitted) +
  geom_point() +
  geom_smooth(se = FALSE, method = "loess", formula = y ~ x) +
  labs(x = "Fitted values",
    y = expression(bold(sqrt(abs("Standardized residuals"))))) +
  ggtitle("Scale-Location")

c <- lm_sh %>.%
  chart(broom::augment(.), .cooksd ~ seq_along(.cooksd)) +
  geom_bar(stat = "identity") +
  geom_hline(yintercept = seq(0, 0.1, by = 0.05), colour = "darkgray") +
  labs(x = "Obs. number", y = "Cook's distance") +
  ggtitle("Cook's distance")

d <- lm_sh %>.%
  chart(broom::augment(.), .std.resid ~ .hat %size=% .cooksd) +
  geom_point(show.legend = FALSE) +
  geom_smooth(se = FALSE, size = 0.5, method = "loess", formula = y ~ x) +
  geom_vline(xintercept = 0) +
  geom_hline(yintercept = 0) +
  labs(x = "Leverage", y = "Standardized residuals") +
  ggtitle("Residuals vs Leverage")
combine_charts(list(a, b, c, d))
```

Le premier graphique (A) permet de vérifier si la distribution des résidus est homogène. Nous pouvons observer ici une bonne distribution des résidus, de manière équilibrée de part et d’autre du zéro à l’ordonnée. Le graphique (B) montre également qu'aucune valeur en particulier de semble influencer la régression. Le troisième graphique d’analyse des résidus (C) montre l’influence qu’ont chacun des individus sur la régression linéaire diagnostiquée. Nous pouvons observer dans ce cas que nous n’avons pas de valeur influençant particulièrement notre régression, car aucune distance de Cook calculée et apparaissant sur ce graphique n’a l’air de sortir grossièrement du lot. Le dernier graphique (D), utilisant l’effet de ‘’Leverage’’, met également en évidence l’influence qu’ont les sujets de l’étude sur le modèle de régression. Ici, aucun des points en question ne semble avoir suffisamment d’influence que pour tirer la droite de régression vers lui de manière abusive.

Essayons maintenant de représenter la même situation mais avec une régression polynomiale. Les critères d'Akaike seront ensuite calculés afin de déterminer quel modèle est le mieux adapté.

```{r}
summary(lm_ph <- lm(data = biometry, masse ~  tour_hanche + I(masse^2)))
lm_ph %>.% (function (lm, model = lm[["model"]], vars = names(model))
  chart(model, aes_string(x = vars[2], y = vars[1])) +
  geom_point() +
  stat_smooth(method = "lm", formula = y ~ x + I(x^2)))(.) +
  ggtitle("Régression linéaire polynomiale, masse en fonction du tour de hanche")
```

Voici une modélisation graphique de la régression polynomiale mettant en évidence la relation entre la masse des individus de l'étude avec leur tour de hanche. Nous pouvons voir que la valeur de R² est cette fois de 0.9832. A première vue, il est difficile de voir si cette modélisation semble mieux représenter la tendance du nuage de points que le précédent. La p-value est inférieure à 2.2e-16 dans ce cas également. Vérifions la fiabilité de notre modélisation en effectuant quelques analyses sur les résidus.

```{r}
e <- lm_ph %>.%
  chart(broom::augment(.), .resid ~ .fitted) +
  geom_point() +
  geom_hline(yintercept = 0) +
  geom_smooth(se = FALSE, method = "loess", formula = y ~ x) +
  labs(x = "Fitted values", y = "Residuals") +
  ggtitle("Residuals vs Fitted")

f <- lm_ph %>.%
  chart(broom::augment(.), sqrt(abs(.std.resid)) ~ .fitted) +
  geom_point() +
  geom_smooth(se = FALSE, method = "loess", formula = y ~ x) +
  labs(x = "Fitted values",
    y = expression(bold(sqrt(abs("Standardized residuals"))))) +
  ggtitle("Scale-Location")

g <- lm_ph %>.%
  chart(broom::augment(.), .cooksd ~ seq_along(.cooksd)) +
  geom_bar(stat = "identity") +
  geom_hline(yintercept = seq(0, 0.1, by = 0.05), colour = "darkgray") +
  labs(x = "Obs. number", y = "Cook's distance") +
  ggtitle("Cook's distance")

h <- lm_ph %>.%
  chart(broom::augment(.), .std.resid ~ .hat %size=% .cooksd) +
  geom_point(show.legend = FALSE) +
  geom_smooth(se = FALSE, size = 0.5, method = "loess", formula = y ~ x) +
  geom_vline(xintercept = 0) +
  geom_hline(yintercept = 0) +
  labs(x = "Leverage", y = "Standardized residuals") +
  ggtitle("Residuals vs Leverage")
combine_charts(list(e, f, g, h))
```

Le premier graphique (A) permet de vérifier si la distribution des résidus est homogène. Nous pouvons observer ici une assez mauvaise distribution des résidus, qui semblent répondre à une fonction extérieure, de part et d’autre du zéro à l’ordonnée. Le graphique (B) accentue encore cette impression. Le troisième graphique d’analyse des résidus (C) montre l’influence qu’ont chacun des individus sur la régression linéaire diagnostiquée. Nous pouvons observer dans ce cas que nous avons deux valeurs influençant particulièrement notre régression, car leur distance de Cook calculée et apparaissant sur ce graphique semble sortir grossièrement du lot. Le dernier graphique (D), utilisant l’effet de ‘’Leverage’’, montre clairement que certains des sujets de l’étude sur le modèle de régression semblent avoir suffisamment d’influence que pour tirer la droite de régression vers eux de manière abusive.

La valeur des critères d'Akaike associés aux deux derniers essais de modélisation a été calculée, mais malgré les résultats obtenus, c'est la régression linéaire simple qui doit être retenue.

```{r}
AIC(lm_sh)
AIC(lm_ph)
```

Le modèle polynomial semble moins approprié pour représenter la relation entre la masse des individus et leur tour de hanche.

Regardons maintenant ce qu'il en est du tour de taille :

```{r}
summary(lm_st <- lm(data = biometry, masse ~ tour_taille))
lm_st %>.% (function (lm, model = lm[["model"]], vars = names(model))
  chart(model, aes_string(x = vars[2], y = vars[1])) +
    geom_point() +
    stat_smooth(method = "lm", formula = y ~ x))(.) +
  ggtitle("Régression linéaire simple, masse en fonction du tour de taille")
```

Voici une modélisation graphique de la régression linéaire mettant en évidence la relation entre la masse des individus de l'étude avec leur tour de taille. Nous pouvons voir que la valeur de R² est de 0.65, la valeur de l'ordonnée à l'origine vaut -13,87 et que la pente de la droite de régression linéaire (en bleu foncé) vaut 98,34. Celle-ci est contenue dans une enveloppe de confiance qui est en bleu clair. La p-value obtenue pour cette modélisation est inférieure à 2,2e-16, au seuil alpha fixé à 0,05. A première vue, cette modélisation semble bien représenter la tendance du nuage de points. Vérifions cela en effectuant quelques analyses sur les résidus.

```{r}
i <- lm_st %>.%
  chart(broom::augment(.), .resid ~ .fitted) +
  geom_point() +
  geom_hline(yintercept = 0) +
  geom_smooth(se = FALSE, method = "loess", formula = y ~ x) +
  labs(x = "Fitted values", y = "Residuals") +
  ggtitle("Residuals vs Fitted")

j <- lm_st %>.%
  chart(broom::augment(.), sqrt(abs(.std.resid)) ~ .fitted) +
  geom_point() +
  geom_smooth(se = FALSE, method = "loess", formula = y ~ x) +
  labs(x = "Fitted values",
    y = expression(bold(sqrt(abs("Standardized residuals"))))) +
  ggtitle("Scale-Location")

k <- lm_st %>.%
  chart(broom::augment(.), .cooksd ~ seq_along(.cooksd)) +
  geom_bar(stat = "identity") +
  geom_hline(yintercept = seq(0, 0.1, by = 0.05), colour = "darkgray") +
  labs(x = "Obs. number", y = "Cook's distance") +
  ggtitle("Cook's distance")

l <- lm_st %>.%
  chart(broom::augment(.), .std.resid ~ .hat %size=% .cooksd) +
  geom_point(show.legend = FALSE) +
  geom_smooth(se = FALSE, size = 0.5, method = "loess", formula = y ~ x) +
  geom_vline(xintercept = 0) +
  geom_hline(yintercept = 0) +
  labs(x = "Leverage", y = "Standardized residuals") +
  ggtitle("Residuals vs Leverage")
combine_charts(list(i, j, k, l))
```

Le premier graphique (A) permet de vérifier si la distribution des résidus est homogène. Nous pouvons observer ici une bonne distribution des résidus, de manière équilibrée de part et d’autre du zéro à l’ordonnée. Le graphique (B) montre également qu'aucune valeur en particulier de semble influencer la régression. Le troisième graphique d’analyse des résidus (C) montre l’influence qu’ont chacun des individus sur la régression linéaire diagnostiquée. Nous pouvons observer dans ce cas que nous n’avons pas de valeur influençant particulièrement notre régression, car aucune distance de Cook calculée et apparaissant sur ce graphique n’a l’air de sortir grossièrement du lot. Le dernier graphique (D), utilisant l’effet de ‘’Leverage’’, met également en évidence l’influence qu’ont les sujets de l’étude sur le modèle de régression. Ici, aucun des points en question ne semble avoir suffisamment d’influence que pour tirer la droite de régression vers lui de manière abusive.

Essayons maintenant de représenter la même situation mais avec une régression polynomiale. Les critères d'Akaike seront ensuite calculés afin de déterminer quel modèle est le mieux adapté.

```{r}
summary(lm_pt <- lm(data = biometry, masse ~  tour_taille + I(masse^2)))
lm_pt %>.% (function (lm, model = lm[["model"]], vars = names(model))
  chart(model, aes_string(x = vars[2], y = vars[1])) +
    geom_point() +
    stat_smooth(method = "lm", formula = y ~ x + I(x^2)))(.) +
  ggtitle("Régression linéaire polynomiale, masse en fonction du tour de taille")
```

Voici une modélisation graphique de la régression polynomiale mettant en évidence la relation entre la masse des individus de l'étude avec leur tour de taille. Nous pouvons voir que la valeur de R² est cette fois de 0.9834. A première vue, il est difficile de voir si cette modélisation semble mieux représenter la tendance du nuage de points que le précédent. La p-value est inférieure à 2.2e-16 dans ce cas également. Vérifions la fiabilité de notre modélisation en effectuant quelques analyses sur les résidus.

```{r}
m <- lm_pt %>.%
  chart(broom::augment(.), .resid ~ .fitted) +
  geom_point() +
  geom_hline(yintercept = 0) +
  geom_smooth(se = FALSE, method = "loess", formula = y ~ x) +
  labs(x = "Fitted values", y = "Residuals") +
  ggtitle("Residuals vs Fitted")

n <- lm_pt %>.%
  chart(broom::augment(.), sqrt(abs(.std.resid)) ~ .fitted) +
  geom_point() +
  geom_smooth(se = FALSE, method = "loess", formula = y ~ x) +
  labs(x = "Fitted values",
    y = expression(bold(sqrt(abs("Standardized residuals"))))) +
  ggtitle("Scale-Location")

o <- lm_pt %>.%
  chart(broom::augment(.), .cooksd ~ seq_along(.cooksd)) +
  geom_bar(stat = "identity") +
  geom_hline(yintercept = seq(0, 0.1, by = 0.05), colour = "darkgray") +
  labs(x = "Obs. number", y = "Cook's distance") +
  ggtitle("Cook's distance")

p <- lm_pt %>.%
  chart(broom::augment(.), .std.resid ~ .hat %size=% .cooksd) +
  geom_point(show.legend = FALSE) +
  geom_smooth(se = FALSE, size = 0.5, method = "loess", formula = y ~ x) +
  geom_vline(xintercept = 0) +
  geom_hline(yintercept = 0) +
  labs(x = "Leverage", y = "Standardized residuals") +
  ggtitle("Residuals vs Leverage")
combine_charts(list(m, n, o, p))
```

Le premier graphique (A) permet de vérifier si la distribution des résidus est homogène. Nous pouvons observer ici une assez mauvaise distribution des résidus, qui semblent répondre à une fonction extérieure, de part et d’autre du zéro à l’ordonnée. Le graphique (B) accentue encore cette impression. Le troisième graphique d’analyse des résidus (C) montre l’influence qu’ont chacun des individus sur la régression linéaire diagnostiquée. Nous pouvons observer dans ce cas que nous avons deux valeurs influençant particulièrement notre régression, car leur distance de Cook calculée et apparaissant sur ce graphique semble sortir grossièrement du lot. Le dernier graphique (D), utilisant l’effet de ‘’Leverage’’, montre clairement que certains des sujets de l’étude sur le modèle de régression semblent avoir suffisamment d’influence que pour tirer la droite de régression vers eux de manière abusive

La valeur des critères d'Akaike associés aux deux derniers essais de modélisation a été calculée, mais malgré les résultats obtenus, c'est la régression linéaire simple qui doit être retenue.

```{r}
AIC(lm_st)
AIC(lm_pt)
```

Encore une fois, c'est le modèle linéaire simple qui semble le plus approprié pour représenter la relation étudiée.

Essayons cette fois de représenter la relation entre les variables qualitatives que sont le fait de fumer ou non et la classe de l'indice de masse corporelle. Sont considérés comme fumeurs les individus qui consomment plus d'une cigarette/sem. :

```{r}
biometry <- mutate(biometry,
  bmi = masse/(taille/100)^2,
  bmi_classe = case_when(
    bmi < 18.5 ~ "Sous_poids",
    bmi >= 18.5 & bmi < 25 ~ "Poids_normal",
    bmi >= 25 & bmi < 30 ~ "Surpoids",
    bmi >= 30 ~ "Obèse" ),
  fumeur = case_when(
    tabac <= 1 ~ "0",
    tabac > 1 ~ "1")
  )

biometry$fumeur <- as.factor(biometry$fumeur) 

biometry <- labelise(biometry,
  label=list(bmi = "IMC", bmi_classe = "classe IMC", fumeur = "fumeur"),
  units=list(bmi = "Kg/cm²"))

biometry$bmi_classe <- ordered(biometry$bmi_classe,
  levels = c("Sous_poids", "Poids_normal", "Surpoids", "Obèse"))
```

Représentons graphiquement la répartition de ces nouvelles variables au sein de notre jeu de données:

```{r}
chart(biometry, ~ bmi_classe %fill=% fumeur) +
  geom_bar()
```

Malheureusement le nombre de données est insuffisant que pour pouvoir interpréter correctement la situation. Essayons alors de représenter la relation entre le milieu de vie (urbain ou non) et la classe de l'indice de masse corporelle.

```{r}
biometry <- mutate(biometry,
  urbain = case_when(
    milieu_vie == "urbain" ~ "1",
    milieu_vie == "rural" ~ "0"))

biometry$urbain <- as.factor(biometry$urbain) 
```

Représentons graphiquement la répartition de ces nouvelles variables au sein de notre jeu de données:

```{r}
chart(biometry, ~ bmi_classe %fill=% urbain) +
  geom_bar()
```

Nous pouvons dès lors étudier grâce au modèle linéaire généralisé la situation en question :

```{r}
biometry_glm <- glm(data = biometry, urbain ~ bmi,
  family = binomial(link = logit))
summary(biometry_glm)
```

Il n'y a apparemment pas de lien significatif entre le fait d'être en surpoids et le fait d'habiter en ville.







